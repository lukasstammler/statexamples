---
title: "Korrelation und Regression"
author: "Lukas Stammler"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_height: 6
    fig_width: 6
    highlight: pygments
    theme: yeti
    code_download: false
    toc: yes
    number_sections: yes
    toc_float: yes
bibliography: book.bib
---

```{r setup, include=FALSE}
rm(list = ls())

knitr::opts_chunk$set(echo = FALSE, message = FALSE)

library(tidyverse)
library(jmv)
library(knitr)
library(kableExtra)
library(openintro)
library(patchwork)

data(COL)
```

Übungssammlung zu Korrelation und linearer Regression

# Sicherheitsgurt {.tabset}  

Quelle: @Agresti2018, Ex. 3.32  

**Wie gut sind Sicherheitsgurte im Auto?** Im Jahre 2013 haben das US Dept. of Transportation
und das Insurance Institute for Highway Sefety Daten erhoben. Die Ergebnisse zeigten, dass für jedes zusätzliche Prozent, das den Sicherheitsgürtel benutzt, die Anzahl der tödlichen Unfälle pro 100'000 Autofahrer:innen um 24.45 abnimmt. $\hat{y}$ ist die vorhergesagte Anzahl tödlicher Unfälle pro 100'000 Autofahrer:innen im Jahr 2013 und $x$ ist der Anteil der Sicherheitsgurt-Nutzer:innen.   

## Aufgabe  

a) Wie gross ist die Steigung $\beta_1$ in unserem Modell $\hat{y} = \beta_0 + \beta_1 x$?  
b) Der Achsenabschnitt $\beta_0$ ist 32.42. Wieviele tödliche Unfälle pro 100'000 Personen sagt unser Modell voraus für 

   i) einen Staat, in dem niemand einen Sicherheitsgurt verwendet? 
   ii) für eine Staat, in dem 74% der Autofahrer:innen einen Sicherheitsgurt verwenden? 
   iii) und für einen Staat, in dem 100% der Autofahrer:innen einen Sicherheitsgurt verwenden?   
   
## Lösung  

a) $\beta_1 = -24.45$  

b) Siehe Code

```{r, echo=TRUE}
## Einfaches lineares Regressionsmodell ----------------------------------------
beta0 <- 32.42
beta1 <- -24.45

## b) i) -----------------------------------------------------------------------
beta0 + beta1 * 0

## b) ii) ----------------------------------------------------------------------
beta0 + beta1 * .74

## b) iii) ---------------------------------------------------------------------
beta0 + beta1 * 1
```

<br/>

# Cerealien {.tabset}  

Quelle: @Agresti2018, Ex. 3.33

**Ist der Zuckergehalt in Frühstückscerealien ein guter Prädiktor für den Natriumgehalt?** 
Die Abbildung unten zeigt das Ergebnis einer Regressionsanalyse für die unabhängige 
Variable $x$ = sugar und die abhängige Variable $y$ = sodium (Natrium) für 20 beliebte 
Frühstückscerealien. 

```{r, fig.align='center', fig.dim=c(5, 4)}
cereal <- read_csv("./data/cereal.csv")

ggplot(cereal, aes(x = Zucker, y = Natrium)) +
  geom_point(size = 3, color = "steelblue", alpha = .6) +
  geom_smooth(method = "lm", color = "darkgreen", se = FALSE) +
  xlab("Zucker (g)")+
  ylab("Natrium (mg)") +
  theme_classic()

cereal_lm <- lm(Natrium ~ Zucker, data = cereal)
summary(cereal_lm)
```

## Aufgabe  

a) Nach welchem Kriterium wurde die grüne Linie im Streudiagramm konstruiert?   
b) Würden Sie den Zuckergehalt als guten Prädiktor für den Natriumgehalt von 
Frühstückscerealien bezeichnen? Begründen Sie.

## Lösung  

a) Die Linie wurde so berechnet, dass die Quadratsumme der Residuen minimal ist.  
b) Nein. $R^2$ ist nahezu 0 (0.54%). Das bedeutet, dass $x$ nur 0.54% der Variabilität 
von $y$ voraussagen kann. Mit einem $p$ von 0.942 unterscheidet sich die Steigung 
$\beta_1$ nicht signifikant von 0.  

<br/>

# Mountainbike {.tabset}

Quelle: @Agresti2018, Ex. 3.41

**Besteht ein Zusammenhang zwischen dem Gewicht und dem Preis eines Mountainbikes?** 
Folgende Angaben sind im Datensatz `mountainbike.csv` gespeichert: Preis in US$, Gewicht in kg 
und Art der Federung (FU = Vollfederung, FE = Vordergabelfederung). Daten aus *Consumer Reports, Juni 1999*.   

```{r}
bikes <- read_csv("./data/mountainbikes.csv")

## pounds in kg umwandeln -----------------------------------------------------
# bikes$Gewicht <- round(bikes$Gewicht * 0.453592, 1)
# write_csv(bikes, "./data/mountainbikes.csv")

# summary(bikes)
```


## Aufgabe

a) Erstellen Sie ein Streudiagramm für Preis und Gewicht.  
b) Berechnen Sie das Regressionsmodell und interpretieren Sie die Steigung $\beta_1$.   
c) Sie möchten ein Mountainbike mit einem Gewicht von 14 kg kaufen. Welchen Preis 
das Modell für ein solches Fahrrad voraus?  
d) Ist das Gewicht ein zuverlässiger Prädiktor für den Preis eines Mountainbikes? 

## Lösung  

a) Erstellen Sie ein Streudiagramm für Preis und Gewicht.  

```{r, echo=TRUE, fig.align='center', fig.dim=c(5, 4)}
plot(bikes$Gewicht, bikes$Preis,
     xlab = "Gewicht (kg)",
     ylab = "Preis (US$)")
abline(lm(Preis ~ Gewicht, data = bikes), col = "darkgreen")
```

* *Schwerere Bikes sind preiswerter als leichtere Bikes. Es besteht ein eher schwacher negativer linearer Zusammenhang zwischen Preis und Gewicht eines Mountainbikes*

b) Berechnen Sie das Regressionsmodell und interpretieren Sie die Steigung $\beta_1$.  

```{r, echo=TRUE}
bikes_lm <- lm(Preis ~ Gewicht, data = bikes)
summary(bikes_lm)
```

$$\widehat{Preis} = 1932.67 - 91.69 \times ~Gewicht$$
* *Mit jedem kg Gewicht, das ein Mountainbike leichter ist, steigt der Preis um 91.69 US$.*   

c) Sie möchten ein Mountainbike mit einem Gewicht von 14 kg kaufen. Welchen Preis sagt das Modell für ein solches Fahrrad voraus?  

```{r}
Gewicht <- 14
Preis <- 1932.67 - 91.69 * Gewicht
print(Preis)
```

d) Ist das Gewicht ein zuverlässiger Prädiktor für den Preis eines Mountainbikes? 

* *Das Gewicht ist ein schwacher Prädiktor für den Preis. $R^2$ ist 0.1072, d.h. die Variable Gewicht kann nur etwa 10% der Variabilität der Variable Preis erklären.*


# Mountainbike 2 {.tabset}

Quelle: @Agresti2018, Ex. 3.42

Wir arbeiten mit den Daten aus der vorigen Übung. Der Datensatz enthält in der Variable Typ Angaben zur Federung: FU = Vollfederung, FE = Vordergabelfederung. 

Die Abbildung zeigt ein Streudiagramm, in dem die Daten für Federung:FU und Federung:FE getrennt dargestellt sind.  

```{r, fig.align='center', fig.dim=c(5, 4)}
ggplot(bikes, aes(x = Gewicht, y = Preis, color = Federung)) +
  geom_point(size = 3) +
  xlab("Gewicht (kg)") +
  ylab("Preis (US$)") +
  theme_classic()
```


## Aufgabe  

a) Erkennen Sie einen linearen Zusammenhang? Ist die einfache Regressionslinie aus der ersten Mountainbike-Aufgabe die beste Art, die Daten darzustellen? Gibt es eine bessere Art, die Daten zu modellieren?   
b) Erstellen Sie für die beiden Federungstypen FE und FU je ein separates Modell und fassen Sie ihr Ergebnis zusammen.   
c) Der Korrelationskoeffizient für alle Daten ist `r round(cor(bikes$Preis, bikes$Gewicht), 3)`. Vergleichen Sie diesen Korrelationskoeffizienten mit den Korrelationskoeffizienten, die Sie separat für die beiden Gruppen FU und FE berchnet haben.   

## Lösung   

a) Erkennen Sie einen linearen Zusammenhang? Ist die einfache Regressionslinie aus der ersten Mountainbike-Aufgabe die beste Art, die Daten darzustellen? Gibt es eine bessere Art, die Daten zu modellieren?   

```{r, fig.align='center', fig.dim=c(5, 4)}
ggplot(bikes, aes(x = Gewicht, y = Preis, color = Federung)) +
  geom_point(size = 3) +
  xlab("Gewicht (kg)") +
  ylab("Preis (US$)") +
  geom_smooth(method = "lm", se = FALSE) +
  theme_classic()
```

* *Es besteht für beide Gruppen ein negativer linearer Zusammenhang. Im Vergleich zur Regressionsgeraden für alle Daten gemeinsam liegen die Punkte nahe an der Geraden, was für einen moderaten bis starken Zusammenhang spricht. Man könnte für beide Federungstypen separate Regressionsmodelle erstellen*

b) Erstellen Sie für die beiden Federungstypen FE und FU je ein separates Modell und fassen Sie ihr Ergebnis zusammen.  

```{r, echo=TRUE}
## Teildatensätze nach Federungstyp erstellen ----------------------------------
bikes_FE <- subset(bikes, Federung == "FE")
bikes_FU <- subset(bikes, Federung == "FU")

## Einfache lineare Regressionsmodelle erstellen -------------------------------
bikes_FE_lm <- lm(Preis ~ Gewicht, data = bikes_FE)  
bikes_FU_lm <- lm(Preis ~ Gewicht, data = bikes_FU)

## Regressionsoutput -----------------------------------------------------------
summary(bikes_FE_lm)
summary(bikes_FU_lm)
```

* Regressionsmodell für den Federungstyp FE    

$$\widehat{Preis} = 2146.26 - 121.75 \times ~Gewicht$$

* Regressionsmodell für den Federungstyp FU   

$$\widehat{Preis} = 2441.90 - 97.70 \times ~Gewicht$$

* *Für beide Modelle unterscheidet sich die Steigung $\beta_1$ signifikant von 0 ($p$ < 0.05). Für Typ FE ist $R^2$ = 0.788 und für Typ FU ist $R^2$ = 0.888. Damit sind diese Modelle wesentlich zuverlässiger für die Vorhersage des Preises für ein Mountainbike nach dem Gewicht, als das erste Modell.*   


c) Der Korrelationskoeffizient für alle Daten ist `r round(cor(bikes$Preis, bikes$Gewicht), 3)`. Vergleichen Sie diesen Korrelationskoeffizienten mit den Korrelationskoeffizienten, die Sie separat für die beiden Gruppen FU und FE berechnet haben.   

```{r, echo=TRUE}
cor(bikes_FE$Preis, bikes_FE$Gewicht)
cor(bikes_FU$Preis, bikes_FU$Gewicht)
```

* *Die Korrelation mit allen Daten ist mit $r$ = `r round(cor(bikes$Preis, bikes$Gewicht), 3)` schwach. Die Korrelationen zwischen Gewicht und Preis für die Mountainbikes getrennt nach Federungstyp sind stark.*   

**Hinweis:** Dieses Beispiel könnte auch mit einem multiplen linearen Regressionsmodell analysiert werden.

$$\widehat{Preis} = \beta_0 + \beta_1 \times Gewicht + \beta_2 \times Federung$$

```{r}
bikes_mlm <- lm(Preis ~ Gewicht + Federung, data = bikes)
summary(bikes_mlm)
```

$$\widehat{Preis} = 2109.64 - 119.16 \times Gewicht + \beta_2 \times 641.28$$

* *Interpretation: Wenn ein Mountainbike ein kg leichter wird, steigt der Preis um durchschnittlich 119.16 US Dollar, $\beta_1$ = 119.16, $p$ < 0.001. Ein vollgefedertes Mountainbike ist im Durchschnitt um 661 US Dollar teurer, als ein Mountainbike mit nur Vordergabelfederung $\beta_2$ = 641.28, $p$ < 0.001. Dieses Modell erklärt 94% der Variabilität der Preise von Mountainbikes, $R_{adj}^2$ = 0.942.*   

<br/>

# Benzinverbrauch {.tabset}  

Quelle: @Agresti2018, Ex. 3.43   

Das Streudiagramm zeigt den Zusammenhang zwischen Benzinverbrauch in l/km und Fahrgeschwindigkeit in km/h für einen Mittelklassewagen. 

```{r, fig.align='center', fig.dim=c(5, 4)}
# benzin <- read_csv("./data/fuel.csv")
# 
# benzin <- benzin %>% 
#   mutate(
#     kmh = velocity * 1.60934,   # mph in kmh
#     kml = mpg * 0.425144        # mpg in km pro l
#   ) %>% 
#   select(kmh, kml)
# write_csv(benzin, "./data/benzin.csv")

benzin <- read_csv("./data/benzin.csv")

ggplot(benzin, aes(x = kmh, y = kml)) +
  geom_smooth(method = "lm", color = "darkgreen", se = FALSE) +
  geom_point(size = 3, color = "steelblue", alpha = 0.7) +
  xlab("Geschwindigkeit (km/h)") +
  ylab("Benzinverbrauch (l/km)") +
  scale_x_continuous(breaks = seq(from = 0, to = 200, by = 20)) +
  theme_minimal()
```


## Aufgabe  

a) Der Korrelationskoeffizient für den Zusammenhang von Benzinverbrauch und Geschwindigkeit ist $r$ = 0.106. Ist der Korrelationskoeffizient ein gutes Mass, um diesen Zusammenhang zu beschreiben?   
b) Eignet sich ein lineares Regressionsmodell, um den Zusammenhang zwischen Geschwindigkeit und Benzinverbrauch zu beschreiben?  
c) Über welchen Unterbereich der Daten würden Sie es in Erwägung ziehen, ein lineares Regressionsmodell zu erstellen?  

<br/>

## Lösung  

a) Der Korrelationskoeffizient für den Zusammenhang von Benzinverbrauch und Geschwindigkeit ist $r$ = 0.106. Ist der Korrelationskoeffizient ein gutes Mass, um diesen Zusammenhang zu beschreiben?  

* *Das Streudiagramm zeigt einen nichtlinearen Zusammenhang zwischen Geschwindigkeit und Benzinverbrauch. Der Korrelationskoeffizient, der ein Mass für einen linearen Zusammenhang ist, hat in diesem Fall keine Aussagekraft.*

b) Eignet sich ein lineares Regressionsmodell, um den Zusammenhang zwischen Geschwindigkeit und Benzinverbrauch zu beschreiben?  

* *Da kein linearer Zusammenhang zwischen Geschwindigkeit und Benzinverbrauch besteht, ist ein lineares Regressionsmodell nicht geeignet.*   

c) Über welchen Unterbereich der Daten würden Sie es in Erwägung ziehen, ein lineares Regressionsmodell zu erstellen?   

* *Entweder über den Bereich zwischen 60 bis 140 km/h oder über den Bereich zwischen 5 bis 60 km/h. In diesen Bereichen ist der Zusammenhang annähernd linear*  

<br/>

# Restaurant-Rating *R-Exams* {.tabset}  

Quelle: @Agresti2018, Ex. 3.28   

Zagat Restaurantführer publiziert Ratings von Restaurants für viele grosse Städte weltweit (www.zagat.com). Das Review für jedes Restaurant umfasst eine Beschreibung und ein 0-30 Punkterating für die Qualität der Speisen, Ausstattung (Dekor), Bedienung und der Preis für eine Mahlzeit inkl. einem Getränk. Für 31 Französische Restaurants in Boston hatte 2014 betrug das Rating für die Qualität der Speisen im Durchschnitt 24.55 Punkte mit einer Standardabweichung von 2.08 Punkten. Die Kosten in US Dollar betrugen im Durchschnitt 50.35 US Dollar mit einer Standardabweichung von 14.92 US Dollar. Das Regressionsmodell, das den Preis in Abhängigkeit von der Qualität der Speisen vorhersagt ist $\hat{y} = -70.04 + 4.90x$. Der Korrelationskoeffizient ist $r$ = 0.68.    

```{r, fig.align='center', fig.dim=c(6, 5)}
zagat <- read_csv("./data/Zagat_Boston.csv")

french <- zagat %>% 
  filter(Type == "French")

ggplot(french, aes(x = Food, y = Cost)) +
  geom_point(size = 3, color = "steelblue") +
  xlab("Rating Qualität der Speisen") +
  ylab("Preis (US Dollar)") +
  ggtitle("Preis ~ Qualität, Boston French Restaurants (2014) ") +
  theme_classic()

french_lm <- lm(Cost ~ Food, data = french)
# summary(french_lm)
```

## Aufgabe  

a) Welche Kosten erwarten Sie für ein Essen im Restaurant mit dem i) tiefsten Rating für die Qualität der Speisen (21 Punkte), mit dem ii) höchsten Rating (28 Punkte).   
b) Interpretieren Sie die Steigung des Regressionsmodells.  
c) Interpretieren Sie die Korrelation.  
d) Wie beurteilen Sie die Zuverlässigkeit des Modells?  
e) Bonus: Zeigen Sie, wie die Steigung aus der Korrelation und den übrigen Angaben berechnet werden kann. 

<br/>

## Lösung  

a) Welche Kosten erwarten Sie für ein Essen im Restaurant mit dem i) tiefsten Rating für die Qualität der Speisen (21 Punkte), mit dem ii) höchsten Rating (28 Punkte).   

```{r, echo=TRUE}
## a) i) -----------------------------------------------------------------------
-70.04 + 4.90 * 21

## a) ii) 
-70.04 + 4.90 * 28
```

* *Wir erwarten, dass bei einem Rating der Speisequalität von 21 Punkten, eine Mahlzeit im Durchschnitt 32.82 US Dollar und bei einem Rating von 28 Punkten im Durchschnitt 67.17 US Dollar kostet.*   

b) Interpretieren Sie die Steigung des Regressionsmodells.  

* *Wenn die Qualität der Speisen um 1 Punkt steigt, steigt der Preis für eine Mahlzeit im Durchschnitt um 4.9 US Dollar.*   

c) Interpretieren Sie die Korrelation.  

* *Es besteht eine positive moderate lineare Korrelation zwischen dem Rating der Speisequalität und dem Preis für eine Mahlzeit.*   

d) Wie beurteilen Sie die Zuverlässigkeit des Modells?  

$$R^2 = r^2$$

```{r, echo=TRUE}
r <- 0.68
r^2
```

* *Das Regressionsmodell erklärt 46.2% der Variabilität der Preise durch das Rating der Qualität der Speisen.*   

e) Bonus: Zeigen Sie, wie die Steigung aus der Korrelation und den übrigen Angaben berechnet werden kann.  

$$\beta_1 = \frac{s_y}{s_x}r$$

```{r, echo=TRUE}
sy <- 14.92
sx <- 2.08
r <- 0.68

beta1 <- (sy/sx) * r
print(beta1)
```

<br/>

# Olympischer Weitsprung {.tabset}  

Quelle: @Agresti2018, Ex. 3.45   

Im Datensatz `jump_long.csv` sind die Siegerdistanzen im olympischen Weitsprung der Männer für die Jahre 1896 bis 2012 abgelegt. Das olympische Jahr ist in der Variablen `Year` und die Siegerdistanz in der Variablen `Meters` gespeichert.   

```{r, fig.align='center', fig.dim=c(5, 5), eval=FALSE}
long <- read_csv("./data/long_jump.csv")  

long_lm <- lm(Meters ~ Year, data = long)
# summary(long_lm)

reg.eq <- "y = -20.5 + 0.0145x"
r.sq <- paste("R^2 == 0.77")

ggplot(long, aes(x = Year, y = Meters)) +
  geom_smooth(method = "lm", color = "darkgreen", se = FALSE) +
  geom_point(size = 3, color = "steelblue") +
  ylab("Distanz (m)") +
  xlab("Jahr") +
  ggtitle("Siegerdistanzen Weitsprung Männer") +
  annotate(geom = "text", x = 1980, y = 7, label = reg.eq, size = 5) +
  annotate(geom = "text", x = 1980, y = 6.8, label = r.sq , size = 5, parse = TRUE) +
  theme_minimal()
```

## Aufgabe   

a) Erstellen Sie ein Streudiagramm für Sprungdistanz und Jahr, berechnen Sie den Korrelationskoeffizienten nach Pearson und interpretieren Sie ihre Resultate.     
b) Erstellen Sie ein Regressionsmodell. Schreiben Sie die Regressionsgleichung auf und interpretieren Sie die Steigung.   
c) Welche Siegerdistanz erwarten Sie für das Jahr 2100? Erwarten Sie, dass unser Modell eine zuverlässige Vorhersage der Siegerdistanz erlaubt?   

<br/>

## Lösung

a) Erstellen Sie ein Streudiagramm für Sprungdistanz und Jahr, berechnen Sie den Korrelationskoeffizienten nach Pearson und interpretieren Sie ihre Resultate. 

```{r, echo=TRUE, fig.align='center', fig.dim=c(5, 4)}
## Datensatz einlesen ----------------------------------------------------------
long <- readr::read_csv("./data/long_jump.csv")  

## Streudiagramm in R-Base erstellen -------------------------------------------
plot(long$Year, long$Meters,
     ylab = "Distanz (m)",
     xlab = "Jahr",
     main = "Siegerdistanz olympischer Weitsprung Männer",
     col = "steelblue")  

## Regressionsgerade eintragen -------------------------------------------------
abline(lm(long$Meters ~ long$Year, data = long), col = "darkgreen")

## Korrelationskoeffizienten nach Pearson berechnen ----------------------------
cor(long$Meters, long$Year)
```

* *Die Daten zeigen eine starke positive lineare Korrelation zwischen Jahr und Siegerdistanz, $r$ = 0.88. Seit 1886 nimmt die Siegerdistanz in der Tendenz im Laufe der Jahre zu.*

b) Erstellen Sie ein Regressionsmodell. Schreiben Sie die Regressionsgleichung auf und interpretieren Sie die Regressionskoeffizienten.   

```{r, echo=TRUE}
long_lm <- lm(long$Meters ~ long$Year, data = long)
summary(long_lm)
```

$$\widehat{Distanz} = -20.45 + 0.0145 \times Jahr$$

* *Mit jedem zusätzlichen Jahr nimmt die Siegerdistanz im Durchschnitt um 0.015 m (1.5 cm) zu, $\beta_1$ = 0.015, p < 0.001. Im Jahre 0 lag die olympische Siegerdistanz bei durchschnittlich -20.45 m, $\beta_0$ = -20.45, p < 0.005 ;).* 

c) Welche Siegerdistanz erwarten Sie für das Jahr 2100? Erwarten Sie, dass unser Modell eine zuverlässige Vorhersage der Siegerdistanz erlaubt?   

```{r}
## Einsetzen von 2100 für x in die Regressionsgleichung ------------------------
-20.45 + 0.0145 * 2100
```

* *Das Modell sagt für 2100 eine durchschnittliche Siegerdistanz im Weitsprung der Männer von 10 m voraus. Die Voraussage extrapoliert über den gemessenen Datenbereich hinaus und ist daher nicht zuverlässig.*   

<br/>

# Klima Basel-Stadt {.tabset}  

Im Datensatz `wetterBS_M.csv` sind die durchschnittlichen `M.temp` und die maximalen `Max.temp` (maximaler Monatsdurchschnitt) Jahrestemperaturen für die Jahre `Year` 1864 bis 2021 abgelegt.    


```{r, fig.align='center', fig.dim=c(5, 4)}
## Daten aufbereiten -----------------------------------------------------------
# wetter <- read_csv("./data/wetterBS.csv")
# wetter$Datum <- str_c(wetter$Year, wetter$Month, sep = "-")
# wetter.M <- wetter %>%
#   filter(Year < 2022) %>% 
#   group_by(Year) %>%
#   summarise(
#     M.temp = mean(Temperature),
#     Max.temp = max(Temperature)
#   )
# write_csv(wetter.M, "./data/wetterBS_M.csv")
wetter <- read_csv("./data/wetterBS_M.csv")

ggplot(wetter, aes(x = Year, y = Max.temp)) +
  geom_point(size = 3, color = "steelblue", alpha = .7) +
  scale_x_continuous(breaks = seq(from = 1860, to = 2030, by = 10)) +
  xlab("Jahr") +
  ylab("Durchschnittstemperatur (°C)") +
  ggtitle("Temperatur Basel-Stadt, Jahresdurchschnitt (1864-2021)") +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

## Aufgabe

a) Erstellen Sie ein eigenes Streudiagramm für die Entwicklung der jährlichen Durchschnittstemperaturen in Basel und ein Regressionsmodell. Intepretieren Sie das Resultat.  
b) Berechnen Sie anhand des Modells die durchschnittliche Jahrestemperatur in Basel für die Jahre 1936 und 2100. Intepretieren Sie ihre Resultate.  
c) Bonus: Denken Sie, eine lineare Regression ist ein gutes Modell für diese Daten. In welchen Bereichen würden Sie einen linearen Zusammenhang vermuten. Erstellen Sie zwei separate Regressionsmodelle für die Periode (1864 bis 1969) und die Periode (1970 bis 2021). Was stellen Sie fest?    

<br/>

## Lösung   

a) Erstellen Sie ein eigenes Streudiagramm und ein Regressionsmodell. Intepretieren Sie das Resultat.  

```{r, fig.align='center'}
## Streudiagramm erstellen -----------------------------------------------------
plot(wetter$Year, wetter$M.temp,
     xlab = "Jahr",
     ylab = "Durchschnittstemperatur (°C)",
     main = "Temperatur Basel-Stadt, Jahresdurchschnitt (1864-2021)")

## Regressionsgerade erstellen -------------------------------------------------
abline(lm(wetter$M.temp ~ wetter$Year, data = wetter), col = "darkgreen") 

## Regressionsmodell erstellen -------------------------------------------------
wetter_lm <- lm(wetter$M.temp ~ wetter$Year, data = wetter)
summary(wetter_lm)
```

$$\widehat{Temperatur} = -20.397 + 0.0154 \times Jahr$$

* *Zwischen 1864 und 2021 nimmt die durchschnittliche Jahrestemperatur im Mittel um 0.0154 °C pro Jahr zu, $\beta_1$ = 0.0154, p < 0.001. Die Variable `Year` erklärt rund 52% der Variabilität der durchschnittlichen Jahrestemperatur.*  

b) Berechnen Sie anhand des Modells die durchschnittliche Jahrestemperatur für die Jahre 1936 und 710 Intepretieren Sie ihre Resultate.   

```{r}
## Einsetzen von 1936 in die Regressionsgleichung ------------------------------
-20.397 + 0.0154 * 1936

## Einsetzen von 710 in die Regressionsgleichung ------------------------------
-20.397 + 0.0154 * 710
```

* *Das Modell sagt eine durchschnittliche Jahrestemperatur für von 9.417 °C für das Jahr 1936 und eine durchschnittliche Jahrestemperatur von -9.5°C für das Jahr 710 voraus. Die Voraussage für das Jahr 710 ist eine Extrapolation über den gemessenen Zeitraum hinaus und liefert keine verlässlichen Ergebnisse.*   

c) Bonus: Denken Sie, eine lineare Regression ist ein gutes Modell für diese Daten. In welchen Bereichen würden Sie einen linearen Zusammenhang vermuten. Erstellen Sie zwei separate Regressionsmodelle für die Periode (1864 bis 1969) und die Periode (1970 bis 2021). Was stellen Sie fest?  

```{r, echo=TRUE}
## r für 1864 bis 1970 ---------------------------------------------------------
wetter_1864 <- subset(wetter, Year < 1970)
wetter_1864_lm <- lm(M.temp ~ Year, data = wetter_1864)  
summary(wetter_1864_lm)

## r für 1970 bis 2021 ---------------------------------------------------------
wetter_1970 <- subset(wetter, Year >= 1970)
wetter_1970_lm <- lm(M.temp ~ Year, data = wetter_1970)  
summary(wetter_1970_lm)
```

* *In der Periode zwischen 1864 und 1969 nimmt die durchschnittliche Jahrestemperatur in Basel im Mittel um 0.0085 °C pro Jahr zu, $\beta_1$ = 0.0085, $p$ < 0.001. In der Periode nach 1970 nimmt die durchschnittliche Jahrestemperatur im Mittel um 0.0464 °C pro Jahr zu, $\beta_1$ = 0.0464, $p$ < 0.001. Die Streuung der Daten in der Periode vor 1970 ist wesentlich grösser $r$ = 0.388 als nach 1970 $r$ = 0.794.*

```{r, fig.align='center', fig.dim=c(6, 4)}
wetter <- wetter %>% 
  mutate(
    Periode = ifelse(Year < 1970, "vor 1970", "nach 1970")
  )

ggplot(wetter, aes(x = Year, y = M.temp, color = Periode)) +
  geom_point(size = 3, alpha = .7) + 
  geom_smooth(method = "lm", se = FALSE) +
  scale_x_continuous(breaks = seq(from = 1860, to = 2030, by = 10)) +
  xlab("Jahr") +
  ylab("Durchschnittstemperatur (°C)") +
  ggtitle("Temperatur Basel-Stadt, Jahresdurchschnitt (1864-2021)") +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


<br/>

# Referenzen  
